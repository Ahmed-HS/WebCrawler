/*
 * This Kotlin source file was generated by the Gradle 'init' task.
 */
package Web.crawler

import ca.rmen.porterstemmer.PorterStemmer
import org.jsoup.Jsoup
import java.io.File

import java.util.*
import java.util.regex.Matcher
import java.util.regex.Pattern
import kotlin.collections.HashSet

class BasicWebCrawler {

    private val visitedLinks: HashSet<String> = HashSet()
    private val toVisit:Queue<String> = LinkedList()
    private val stemmer: PorterStemmer = PorterStemmer()
    val invertedIndex: MutableMap<String,MutableSet<Pair<String,Int>>> = mutableMapOf()
    val stopWords:Set<String> = File("StopWords.txt").readLines().toSet()


    fun crawl(URL: String, cyclesNumber: Int = 10) {

        toVisit.add(URL)
        var cycle = 0
        while (toVisit.isNotEmpty() && cycle < cyclesNumber)
        {
            cycle++

            val link = toVisit.poll()
            visitedLinks.add(link)
            println(link)
            //1. Fetch the HTML page
            val document = Jsoup.connect(URL).get()

            //val document = Jsoup.parse(File("test.html"),null)

            //2. Parse the HTML to extract the links
            val linksOnPage = document.select("a[href]")

            //3. Get all the text on the page
            val bodyText = document.select("body").text()

            //println(bodyText)

            val tokenizer: Pattern = Pattern.compile("[a-zA-Z]+")

            val matcher: Matcher = tokenizer.matcher(bodyText)

            var position: Int = 0

            while (matcher.find())
            {
                val word = matcher.group().toLowerCase()
                //println(word)
                val stem = stemmer.stemWord(word)
                //println(stem)

                if(!stopWords.contains(stem))
                {
                    invertedIndex[stem] = invertedIndex.getOrDefault(stem, mutableSetOf())
                            .apply {
                                add( link to position)
                            }
                }

                position++
            }

            //4. For each extracted URL add it to the toVisit list
            for (newLink in linksOnPage)
            {
                val linkUrl = newLink.attr("abs:href")
                if(!visitedLinks.contains(linkUrl))
                {
                    toVisit.add(linkUrl)
                }
            }

        }
    }

}

fun main(args: Array<String>) {

    val wrrryyy = "https://tender-shannon-bc1412.netlify.app/"
    val cnn = "http://www.cnn.com"
    val google = "http://www.google.com"
    val crawler = BasicWebCrawler()
    crawler.crawl(cnn,40)
    val result = crawler.invertedIndex

    for ((word,list) in result)
    {
        println(word)
        println(list)
    }
}
